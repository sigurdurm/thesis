% Chapter 1

\chapter{Introduction} % Write in your own chapter title
\label{Chapter1}
\lhead{Chapter 1. \emph{Introduction}} % Write in your own chapter title to set the page header

\section{Motivation}
We live in a world where data is being generated at an amazing rate everywhere around us. Data can describe characteristics of e.g. Internet activities, social interactions, user behaviour in games, mobile phone activities, scientific experiments and measurements from different devices and sensor equipments. The amount of data that is being registered and stored around us is growing massively in volume and complexity. Organizations are storing more and more historic data than before, moving from large databases towards more commonly online distributed file systems or storage web services (e.g. Hadoop, Google, Amazon) providing scalability and high availability at commodity costs where \textit{petabytes} ($10^{15} = 1.000$ \textit{terabytes}) of information can be stored. We live in a world of \textit{Big Data}, exploring unknown patterns and structures without knowing where they will lead us in the future. 

\null
% Now comes the "Funny Quote", written in italics
\textit{``Information is the oil of the 21st century, and analytics is the combustion engine.''}

\begin{flushright}
Peter Sondergaard, senior VP at Gartner
\end{flushright}

In digital games, data about in-game user interactions have been logged and behaviour analyzed since the first game was created. Analysis of the user experience and player behaviour have mostly been done in laboratories in the past, both during game development and after game launch to see if the game was played as designed. Game designs have become increasingly complex in the recent years, offering much more freedom to the players by increasing the number of actions available, items to interact with and Massively Multi-player Online (MMO) persistent worlds that continue to exist after a player exits a game \citep{Kim:2008Tracking, Drachen:2011Evaluating}. This complexity generates much more user-centric data than before and is increasingly challenging when evaluating game designs \citep{Pagulayan:2002UserDesign, Seif:2013GameAnalytics}. The user interactions being registered are called \textit{user telemetry} which is translated to \textit{game metrics} as referred to in game development, providing detailed and objective numbers, e.g. total playtime, monsters killed, puzzles solved.

Collecting user's telemetry can give very detailed quantitative information on player behaviour, and using data mining techniques can supplement traditional qualitative approaches with large-scale behavioural analysis \citep{Yannakakis:2012}, for example show where users are getting stuck and finding actionable behavioural profiles \citep{Kim:2008Tracking, Drachen:2012, Drachen:2011Evaluating}. In the recent years, user behaviour analysis have in part been driven by the emergence of MMO games and Free-to-Play (F2P) games which can have millions of users and objects, which can form highly complex interactions. These game models, especially of persistent nature, are monitoring users actions and their behaviours to drive their revenue with subscriptions or offer players the opportunity to buy virtual items via micro transactions \citep{Kim:2008Tracking, Drachen:2011Evaluating, Fields:2011SocialGame, Seif:2013GameAnalytics}. 

One way of doing a behavioural analysis is to use an unsupervised machine learning technique called clustering. Cluster analysis is a popular exploratory data mining technique that groups sets of data objects together in a cluster that are more similar to each other than the data objects in other groups \citep{Xu:2005Clustering}. Human beings categorize or classify a new object or a phenomenon based on similarity or dissimilarity of the object's descriptive features and this is one of most primitive activities of humans \citep{Anderberg:1973ClusterAnalysis}. Clustering explores the unknown patterns of the data and provides compressed data representation for large-scale data. In computer games, cluster analysis or behavioural categorization can find behavioural profiles that are actionable and give high valuable insights into the game development as well as increasing the monetization \cite{Drachen:2009Tomb, Mahlmann:2010Tomb}. 

Many clustering algorithms are designed for modern sizes of datasets where the whole dataset can fit into memory or allowing few passes (accesses) into a database (where each data object is read more than once). It can be very expensive to analyze large-scale datasets, and to get answers efficiently, one needs to reduce the set of data to be analyzed, e.g. sample fewer players and have fewer features (dimensions) to be compared. Computations for large-scale data take time and need to be distributed to be able to complete in reasonable amount of time. Google's MapReduce programming model was introduced in 2004 \citep{Dean:2004} and allows automatic parallelization and distribution of computations on large clusters of commodity computers. Allowing programmers and researchers to easily implement highly scalable algorithms to process large amounts of data using the MapReduce model without worrying about handling failures and distributing the data with a large amount of complex code. 

\section{Problem Statement}
{\addtolength{\leftskip}{5mm} How can incremental clustering find general player behaviour in multiple batches of behavioural game metric data in a reasonable time? \par}

Considering the massive size of user telemetry data being logged and processed, and the complexity of game designs. There is a knowledge gap when it comes to analyzing such large-scale data efficiently. Number of players are increasing and the complexity of player-game and player-player interactions grows exponentially. The largest massively multiplayer online role-playing game (MMORPG) \textit{World of Warcraft}~\footnote{http://en.wikipedia.org/wiki/World\_of\_Warcraft} had a population around of 10 million users (in 2012 from MMOData~\footnote{http://mmodata.blogspot.com}), where players live in a persistent world that can create many millions of different and complex interactions in the game. 

User telemetry from games can arrive in daily chunks and need to be processed incrementally (in mini batches). There is a need for algorithms that can process massive amount of data that doesn't fit in a computer memory to extracts knowledge in a reasonable time. 

The goal with this project is to implement a scalable clustering algorithm to find the general behaviour in a specific real life game dataset in collaboration with GameAnalytics (GA) \citep{GA2013}. GA is a Software as a Service (SaaS) start-up, a data and analytics engine for game studios with its headquarters located in Copenhagen, analyzing large quantities of game metric data that need to be processed efficiently, returning actionable results to aid game design and development.  

The successful outcome of this project depends upon:
\begin{itemize}
\item An efficient and scalable MapReduce clustering algorithm finding centroids in clusters describing the general behaviour of a real life game dataset provided by GA.
\item The algorithm must be able to cluster multiple data batches incrementally and efficiently, where data chunks of game metric data arrive daily.
\item The algorithm must find high quality centroids between multiple data batches.
\item The general behaviour found must be intuitively interpretable and actionable to game developers.
\end{itemize}

\section{Method}
A k-means clustering algorithm in the MapReduce framework was implemented, enabling the high scalability and fault tolerance offered by MapReduce. Also a k-means start-up program was implemented that processes each data batch individually, running $n$-iterations of the MapReduce k-means clustering algorithm, which in the end returns the centroids for the clusters found in the data batch. These centroids are then used as input for the next clustering process, when the next data batch arrives. The MR k-means algorithm finds the nearest centroid for each point (player behaviour feature vector) in a \textit{Map} function in MR and assigns it to the nearest centroid, then a \textit{Reducer} MR function updates the centroids such that they they represent the current general behaviour.

Different MapReduce strategies were tested, e.g. implementing the \textit{Combiner} function that is executed straight after the \textit{Map} function has finished, minimizing the data transfer inside the MapReduce framework. Different methods in computing the distances from player behaviour data vectors to array of centroids, to find the nearest one centroid was implemented and tested. Such as the naive solution of processing each point and computing the distance by iterating over all the centroids and then over all the features/attributes and calculating the error. The other computing strategies were implemented and tested, using vector and array operations and also finding a distance matrix for all the points and the centroids by holding all the points in memory in the Mapper phase.

As recommended by GA, the \textit{Python} programming language was used for the implementation under the 64-bit Linux (Ubuntu virtual box) operating system, ensuring compatibility with various libraries. The open-source Python MapReduce development framework \textit{mrjob} was used and allows the programmer to easily implement the Map/Combine and Reduce functions needed. Mrjob enables the MR jobs to be easily run locally and in the cloud using the Amazon EMR web service. Python \textit{vectorisation} libraries, such as \textit{NumPy/SciPy}, were used to increase computing efficiency by groupping element-wise operations when manipulating data arrays. 

\section{Contributions}
A MapReduce k-means clustering algorithm that incrementally processes multiple batches of data that e.g. arrive daily in chunks. The algorithm uses centroids from the previous data batch as input for the next data batch. Allowing the centroids of the data population seen before to adjust/move the centroids slowly to the current data batch without loosing too much of the effect from historic data.

The algorithm was evaluate using a real game data set from GA, where the clusters quality was measured after each data batch. Different number of clustering iterations on each data batch were compared, to see how much the cluster quality worsens between data batches or how stable it is. The multiple data batches are sorted after time and the oldest file is processed first, simulating the processing of data that arrive in chunks consecutively. 

The MR k-means algorithm is also evaluated on a generated fictive data where three distributions of normal distributions or clusters move over multiple data batches, creating shifting centroids in the data. General player behaviours were interpreted from feature vectors (centroids) found in the game dataset. Various scalability (scale-out and scale-up) and efficient computations (computing the nearest centroid) were also evaluated using Amazon EMR.

The main results in this thesis shows that the MR k-means clustering algorithm finds general player behaviour by incrementally cluster multiple batches of real game data, and finds good quality clusters when performing low number of iterations on each data batch. The results also show that the algorithm is efficient and scalable, and can easily be run using the Amazon EMR web service.

\section{Project Outline}
References are cited by index in the bibliography and are in order of appearance, e.g. [2] is a citation number two that is referenced in the thesis. Referring to other sections is by the number of that section, e.g. 4.1.2.

The organization of the thesis is as follows: 
\begin{itemize}
\item \textbf{Chapter 2 - Background} Describes a short background theory about clustering player behaviour and the MapReduce framework for large-scale data parallel processing.
\item \textbf{Chapter 3 - Related Work} Overview of related and recent work regarding clustering player behaviour and large-scale data with k-means as focus.
\item \textbf{Chapter 4 - Methodology} Design and implementation work is described; Description of the real game dataset and selection of features, the k-means algorithm in MapReduce and the experimental set-up.
\item \textbf{Chapter 5 - Results} Experiment results and observations are explained.
\item \textbf{Chapter 6 - Discussions} Discussions about the experiment results.
\item \textbf{Chapter 7 - Conclusions} Conclusions are drawn from the study including future research.
\end{itemize}
